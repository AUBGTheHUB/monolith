# Prerequisites
# Be familiar with GitHub environments for deployment: https://docs.github.com/en/actions/managing-workflow-runs-and-deployments/managing-deployments/managing-environments-for-deployment
# Be familiar with Deploying with GitHub Actions: https://docs.github.com/en/actions/use-cases-and-examples/deploying/deploying-with-github-actions
# Be familiar with Passing information between jobs: https://docs.github.com/en/actions/writing-workflows/choosing-what-your-workflow-does/passing-information-between-jobs

name: Deployment Pipeline DEV

on:
  # Manual triggering
  workflow_dispatch:
  push:
    branches:
      - 'main'
    paths:
      # Back-end Paths that will trigger the pipeline
      - 'services/py-api/src/**'
      - 'services/py-api/Dockerfile'
      - 'services/py-api/**/*.lock'
      - 'services/py-api/**/*.toml'

      # Front-end paths that will trigger the pipeline
      - 'services/web/src/**'
      - 'services/web/Dockerfile'
      - 'services/web/package-lock.json'
      - 'services/web/package.json'
      - 'services/web/nginx.*.conf'
      - 'services/web/*.config.*'
      - 'services/web/tsconfig.*'
      - 'services/web/*.html'

      # Changes to the swarm config will also trigger the pipeline
      - 'docker-swarm-stack.yml'


# This is needed so we can push to Container registry
# https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry#authenticating-with-a-personal-access-token-classic
permissions:
  packages: write

jobs:
  detect-changes:

    runs-on: ubuntu-latest

    outputs:
      web_changed: ${{ steps.changed-files-web.outputs.any_changed }}
      py_api_changed: ${{ steps.changed-files-py-api.outputs.any_changed }}
      stack_changed: ${{steps.changed-files-stack.outputs.any_changed }}
      manual_deploy: ${{ github.event_name == 'workflow_dispatch'}}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Get changed files for WEB
        id: changed-files-web
        uses: tj-actions/changed-files@v46
        with:
          # https://github.com/tj-actions/changed-files?tab=readme-ov-file#inputs-%EF%B8%8F
          files: |
            services/web/src/**
            services/web/Dockerfile
            services/web/package-lock.json
            services/web/package.json
            services/web/nginx.*.conf
            services/web/*.config.*
            services/web/tsconfig.*
            services/web/*.html

      - name: Get changed files for PY-API
        id: changed-files-py-api
        uses: tj-actions/changed-files@v46
        with:
          # https://github.com/tj-actions/changed-files?tab=readme-ov-file#inputs-%EF%B8%8F
          files: |
            services/py-api/src/**
            services/py-api/Dockerfile
            services/py-api/**/*.lock
            services/py-api/**/*.toml

      - name: Get changed files for Stack Config
        id: changed-files-stack
        uses: tj-actions/changed-files@v46
        with:
          files: |
            docker-swarm-stack.yml

      - name: Echo change detection results (for debugging)
        run: |
          echo "Web changed: ${{ steps.changed-files-web.outputs.any_changed }}"
          echo "Py-Api changed: ${{ steps.changed-files-py-api.outputs.any_changed }}"
          echo "Stack changed: ${{ steps.changed-files-stack.outputs.any_changed }}"
          echo "Manual deploy: ${{ github.event_name == 'workflow_dispatch'}}"

  build-and-push-images:
    # This job builds images conditionally using optimized BuildKit caching.
    # https://docs.docker.com/build/ci/github-actions/cache/#cache-mounts
    needs: detect-changes
    if: |
      github.ref_name == 'main' &&
      (needs.detect-changes.outputs.web_changed == 'true' ||
      needs.detect-changes.outputs.py_api_changed == 'true' ||
      needs.detect-changes.outputs.manual_deploy == 'true')

    runs-on: ubuntu-latest

    outputs:
      web_built: ${{ steps.build-web.outcome == 'success' }}
      py_api_built: ${{ steps.build-py-api.outcome == 'success' }}

    environment:
      name: DEV
      url: https://${{vars.DOMAIN}}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to the Container registry
        uses: docker/login-action@v3
        with:
          registry: https://ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # --- Build WEB ---
      - name: Restore npm cache from GHA
        id: cache-npm
        uses: actions/cache@v4
        with:
          # Path on the runner where the npm cache will be stored (if it does not exist) or restored from
          path: /tmp/npm-cache
          # Key based on OS, lock file hash. Changes to lock file would invalidate cache, resulting in a cache miss.
          key: ${{ runner.os }}-npm-${{ hashFiles('**/services/web/package-lock.json') }}
          # Fallback keys if exact match not found. This will result in a stale (partial) cache hit (e.g. get cache
          # from an older run). This is helpful if only certain dependencies have changed. In this way the package
          # manager is not going to download all dependencies again, but only those that have changed. (it compares the
          # versions stored in the lock_file to the ones stored in the cache folder).
          # NOTE: If we restore cache using restore keys, the cache-hit output will be 'false'.
          # https://github.com/actions/cache?tab=readme-ov-file#example-cache-workflow
          restore-keys: |
            ${{ runner.os }}-npm-

      - name: Inject npm cache for BuildKit (WEB)
        # Run only if cache was restored or web has changed, or we are manually deploying
        if: steps.cache-npm.outputs.cache-hit == 'true' || needs.detect-changes.outputs.web_changed == 'true' || needs.detect-changes.outputs.manual_deploy == 'true'
        uses: reproducible-containers/buildkit-cache-dance@v3
        with:
          cache-map: |
            # The path restored by actions/cache : the 'target' in the web Dockerfile's RUN --mount=type=cache
            {
              "/tmp/npm-cache": "/root/.npm"
            }

      - name: Build and push Docker image WEB
        id: build-web
        if: needs.detect-changes.outputs.web_changed == 'true' || needs.detect-changes.outputs.manual_deploy == 'true'
        uses: docker/build-push-action@v6
        with:
          context: ./services/web/
          push: true
          tags: |
            ghcr.io/aubgthehub/monolith-web:latest
            ghcr.io/aubgthehub/monolith-web:${{ github.sha }}
          build-args: |
            VITE_ENV=${{vars.VITE_ENV}}
            DOMAIN=${{vars.DOMAIN}}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          # Ensure BuildKit is used (referencing the setup buildx step)
          builder: ${{ steps.buildx.outputs.name }}

      # --- Build PY-API (Poetry) ---
      - name: Restore Poetry cache from GHA
        id: cache-poetry
        uses: actions/cache@v4
        with:
          # Path on the runner where the npm cache will be stored (if it does not exist) or restored from
          path: /tmp/poetry-cache
          # Key based on OS, lock file hash. Changes to lock file would invalidate cache, resulting in a cache miss.
          key: ${{ runner.os }}-poetry-${{ hashFiles('**/services/py-api/poetry.lock') }}
          # Fallback keys if exact match not found. This will result in a stale (partial) cache hit (e.g. get cache
          # from an older run). This is helpful if only certain dependencies have changed. In this way the package
          # manager is not going to download all dependencies again, but only those that have changed. (it compares the
          # versions stored in the lock_file to the ones stored in the cache folder).
          # NOTE: If we restore cache using restore keys, the cache-hit output will be 'false'.
          # https://github.com/actions/cache?tab=readme-ov-file#example-cache-workflow
          restore-keys: |
            ${{ runner.os }}-poetry-

      - name: Inject Poetry cache for BuildKit (PY-API)
        # Run only if cache was restored or py-api has changed, or we have manually triggered the pipeline
        if: steps.cache-poetry.outputs.cache-hit == 'true' || needs.detect-changes.outputs.py_api_changed == 'true' || needs.detect-changes.outputs.manual_deploy == 'true'
        uses: reproducible-containers/buildkit-cache-dance@v3
        with:
          cache-map: |
            # The path restored by actions/cache : the 'target' in the web Dockerfile's RUN --mount=type=cache
            {
              "/tmp/poetry-cache": "/tmp/poetry_cache"
            }

      - name: Build and push Docker image PY-API
        id: build-py-api
        if: needs.detect-changes.outputs.py_api_changed == 'true' || needs.detect-changes.outputs.manual_deploy == 'true'
        uses: docker/build-push-action@v6
        with:
          context: ./services/py-api/
          push: true
          tags: |
            ghcr.io/aubgthehub/monolith-backend:latest
            ghcr.io/aubgthehub/monolith-backend:${{ github.sha }}
          build-args: |
            ENV=${{vars.ENV}}
            DOMAIN=${{vars.DOMAIN}}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          # Ensure BuildKit is used
          builder: ${{ steps.buildx.outputs.name }}

      - name: Echo build outcomes (for debugging)
        # Use always() to run this even if a build step is skipped or fails
        if: always()
        run: |
          echo "Build Web Step Outcome: ${{ steps.build-web.outcome }}"
          echo "Build Py-Api Step Outcome: ${{ steps.build-py-api.outcome }}"

  deploy-to-dev:
    # This job deploys using specific commit hashes for changed services.
    needs: [ detect-changes, build-and-push-images ]
    # Run this job IF the branch is main AND
    # (EITHER web was built OR py-api was built in the build job OR deploy is forced)
    if: |
      github.ref_name == 'main' &&
      (needs.build-and-push-images.outputs.web_built == 'true' ||
       needs.build-and-push-images.outputs.py_api_built == 'true' ||
       needs.detect-changes.outputs.stack_changed == 'true'||
       needs.detect-changes.outputs.manual_deploy == 'true')

    runs-on: ubuntu-latest

    environment:
      name: DEV
      url: https://${{vars.DOMAIN}}

    steps:
      - name: Checkout code # Needed for docker-swarm-stack.yml
        uses: actions/checkout@v4

      - name: Create env file for deploy
        id: create-env
        run: |
          echo "Preparing envfile for deployment..."
          # If web was successfully built OR deploy is forced, set the WEB hash
          if [[ "${{ needs.build-and-push-images.outputs.web_built }}" == "true" || "${{ needs.detect-changes.outputs.manual_deploy }}" == "true" ]]; then
            echo "WEB_GIT_COMMIT_HASH=${{ github.sha }}" >> ./envfile
            echo "-> Setting WEB_GIT_COMMIT_HASH" # Debug message
          else
            echo "-> Skipping WEB_GIT_COMMIT_HASH (web not built and deploy was not manually triggered" # Debug message
          fi

          # If py-api was successfully built OR deploy is forced, set the PY_API hash
          if [[ "${{ needs.build-and-push-images.outputs.py_api_built }}" == "true" || "${{ needs.detect-changes.outputs.manual_deploy }}" == "true" ]]; then
            echo "PY_API_GIT_COMMIT_HASH=${{ github.sha }}" >> ./envfile
            echo "-> Setting PY_API_GIT_COMMIT_HASH" # Debug message
          else
            echo "-> Skipping PY_API_GIT_COMMIT_HASH (py-api not built and deploy was not manually triggered)" # Debug message
          fi

          echo "Contents of ./envfile:"
          cat ./envfile

      # Below we use a GitHub Actions template that is created for the purpose of deploying utilizing both Docker Stack and Docker Context.
      # You can find the source repo here: https://github.com/cssnr/stack-deploy-action
      # name - This will be used as a tag to the Docker Stack that we are going to deploy to Docker Swarm installed on the VPS
      # file - The docker stack config file, it similar to a docker-compose file, but also quite different
      # host - The domain of the target deployment VPS
      # user - The user created on the VPS that has docker privilleges (Can only run docker command)
      # ssh_key - The private ssh key that is used to authenticate into the VPS user that we are utilizing for deployment (Should be stored in the repository secrets)
      # and finally we pass the ./envfile that was created by the step above in the working directory of the GitHub Actions runner.
      # This ./envfile is sourced by the runner and then used by docker stack when doing docker stack deploy to the VPS to pull the latest project image.
      # Links for further reading
      # Read more about Docker Stack: https://docs.docker.com/reference/cli/docker/stack/deploy/
      # Read more about Docker Swarm: https://forums.docker.com/t/docker-swarm-series-8th-publishing-modes/136972
      # Read more about Docker Context:  https://docs.docker.com/engine/manage-resources/contexts/
      - name: Docker Stack Deploy
        uses: cssnr/stack-deploy-action@v1
        with:
          name: monolith
          file: docker-swarm-stack.yml
          host: ${{secrets.VPS_IP}}
          user: deploy
          ssh_key: ${{secrets.DEV_DEPLOY_SSH_PRIVATE_KEY}}
          env_file: ./envfile
